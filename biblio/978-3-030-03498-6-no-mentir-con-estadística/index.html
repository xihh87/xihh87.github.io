<!doctype html><html lang=es-mx><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Anotaciones acerca de «Cómo no mentir con estadística»</title><link rel=stylesheet media=screen href=https://joshua.haase.mx/css/theme.min.2ee1317322f9eb9b2ef0a618d19b20e38c11f5f9c310751400a45db225dd2626.css integrity="sha256-LuExcyL565su8KYY0Zsg44wR9fnDEHUUAKRdsiXdJiY="></head><body><main><article><h1>Anotaciones acerca de «Cómo no mentir con estadística»</h1><nav id=TableOfContents><ul><li><a href=#sinónimos>Sinónimos</a></li></ul><ul><li><a href=#suposiciones-de-la-prueba-t>Suposiciones de la Prueba T</a></li><li><a href=#alternativas>Alternativas</a></li></ul><ul><li><a href=#anova-de-una-vía>ANOVA de una vía</a><ul><li><a href=#suposiciones-de-la-anova-de-una-vía>Suposiciones de la ANOVA de una vía</a></li><li><a href=#grados-de-libertad>Grados de libertad</a></li></ul></li><li><a href=#anova-de-varias-vías>ANOVA de varias vías</a></li><li><a href=#anova-con-medidas-repetidas>ANOVA con medidas repetidas</a></li></ul><ul><li><a href=#cómo-calcular-el-poder-de-un-diseño-experimental>Cómo calcular el poder de un diseño experimental</a></li></ul><ul><li><ul><li><a href=#comparación-entre-ajuste-de-modelo-anova-y-prueba-t>Comparación entre ajuste de modelo, ANOVA y prueba $t$</a></li><li><a href=#suposiciones-para-correlación-de-pearson>Suposiciones para correlación de Pearson</a></li></ul></li></ul><ul><li><ul><li><a href=#resumen>Resumen</a></li></ul></li></ul><ul><li><ul><li><a href=#razones-por-las-que-los-experimentos-son-problemáticos>Razones por las que los experimentos son problemáticos</a></li></ul></li></ul><ul><li><a href=#preregistro>Preregistro</a><ul><li><a href=#problemas>Problemas</a></li></ul></li><li><a href=#análisis-estadísticos-alternativos>Análisis estadísticos alternativos</a></li><li><a href=#el-rol-de-la-replicación>El rol de la replicación</a></li></ul></nav><h1 id=1-no-tomar-decisiones-con-información-incompleta><a href=#1-no-tomar-decisiones-con-informaci%c3%b3n-incompleta alt>1. No tomar decisiones con información incompleta.</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>Se necesita la sensibilidad y la incidencia para estimar la probabilidad con teorema de Bayes.</p><p>$P(A \land B) = P(A) \times P(B)$</p><p>$P(A \lor B) = P(A) + P(B) - P(A \land B)$</p><p>$P(A | B) = \frac{ P(A \land B) }{ P(B) }$</p><p>$P(B | A) = \frac{ P(B \land A) }{ P(A) }$</p><p>$P(A | B) = \frac{P(B | A) \times P(A) }{ P(B) }$</p><p>Caso de VIH con prueba positiva.</p><p>$P(VIH+ | T+) = \frac{ P(T+ | VIH+) \times P(VIH+) }{P(T+ | VIH-) \times P(VIH-) + P(T+ | VIH+) \times P(VIH+) }$</p><p>$P(VIH+) = 0.0001$</p><p>Sensitivity = 0.9999 -> $P(T+ | VIH+) = 0.9999$</p><p>Specificity = 0.9999 -> $P(T- | VIH-) = 0.9999$</p><p>Recomendación de libro: Math on Trial [@isbn:978-0-465-03292-1 ]</p><p>Calcular la razón de las probabilidades (Odds Ratio).</p><p>Si el efecto principal es grande $OR_{AB} = \frac{ P(A) }{ P(B) }$ es un gran indicador.</p><p>Si el efecto principales pequeño, no es tan importante preocuparse acerca de esta proporción.</p><h1 id=2-teoría-de-detección-de-señales><a href=#2-teor%c3%ada-de-detecci%c3%b3n-de-se%c3%b1ales alt>2. Teoría de Detección de Señales</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>Para discriminar usamos dos estadísticos.</p><p><del>Sensibilidad</del> Discriminabilidad teórica: $d&rsquo; = \frac{ señal }{ ruido }$</p><p><del>Sensibilidad</del> Discriminabilidad empírica: $d&rsquo;_{emp} = \lvert z(P(Verdadero<del>positivo)) - z(P(Falso</del>positivo)) \rvert$</p><p>Sesgo (bias) $b_{emp} = \frac{ z(P(Verdadero<del>positivo)) + z(P(Falso</del>positivo)) }{ 2 }$</p><p>Suposiciones para modelo de sensibilidad empírica:</p><ol><li>The underlying probability distributions are Gaussian.</li><li>The Gaussian have the same variance.</li><li>The criterion is not changed during the measurements.</li></ol><p>Assumption 1 is crucial since we compute the z-transform, i.e., the inverse Gaussian distribution, which only makes sense when the data are Gaussian distributed. Assumption 1 is often fulfilled.</p><p>Assumption 2 is usually fulfilled since the stimulus alternatives are similar.</p><p>Assumption 3 is crucial and is not easy to check.</p><p>$d&rsquo;$ también se conoce como efecto estandarizado porque está dividido entre la desviación estándar.</p><p><strong>NOTA</strong>: esta sensibilidad es diferente de la sensibilidad en medicina que es la proporción de verdaderos positivos.</p><p>Las medidas de sensibilidad $P(verdaderos<del>positivos) | $P(respuestas</del>correctas)$ y especificidad $P(verdaderos~negativos)$ confunden el criterio con la discriminabilidad.</p><p>Se puede usar una medida de discriminabilidad para desenredar el criterio y la discriminabilidad.</p><p>La medida de discriminabilidad es independiente del criterio, pero no del modelo.</p><h1 id=3-conceptos-clave-de-estadística><a href=#3-conceptos-clave-de-estad%c3%adstica alt>3. Conceptos clave de estadística</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>$p-value$ confunde el efecto con el tamaño de muestra.</p><p>La discriminabilidad también se conoce como tamaño de efecto o $δ$ de Cohen.</p><p>$d&rsquo; = δ = z(Poder~Estadístico)$</p><h2 id=sinónimos><a href=#sin%c3%b3nimos alt>Sinónimos</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Poder estadístico, $P(rechazo(H_0) | H_1)$, $P(verdaderos~positivos)$, Tasa de éxito.</p><p>$P(falsos<del>positivos)$, $P(falsa</del>alarma)$, Error de tipo I.</p><p>$P(falsos~negativos)$, Tasa de fallo, Error de tipo II.</p><p>Discriminabilidad $d&rsquo;$, $δ$ de Cohen, tamaño de efecto, tamaño de efecto estandarizado.</p><p>Distribución normal, distribución gaussiana, curva de Bell.</p><p>Valores de muestra, calificación, score.</p><p>La prueba t consiste en aplicar la medida de discriminabilidad a los estimados de las muestras:</p><p>$t = \frac{ \bar{x_1} - \bar{x_2} }{ s_{\bar{x_1} - \bar{x_2}} }$</p><p>$s_{\bar{x_1} - \bar{x_2}} = s \sqrt{\frac{ 1 }{ n_1 } + \frac{ 1 }{ n_2 }}$</p><p>Sólo puede haber buenas conclusiones si se conoce el tamaño del efecto y el tamaño de muestra.</p><blockquote><p>Hence, even very small effect sizes can produce a significant result when the sample size is sufficiently large.
Hence, not only large effect sizes lead to significant results as one might expect,
any non-zero effect size leads to significant results when n is large enough.</p></blockquote><p>Modelo de error estándar:</p><p>$x_i = µ + ε_i$</p><p>$µ_ε = 0$, $PDF(ε) = distribución~normal$</p><p>Modelo de error en biología:</p><p>$medición{individuo,tiempo} = media + efecto~personal_{individuo} + error_{individuo,tiempo}$</p><p>$x_{ij} = µ + ν_i + ε_{ij}$</p><p>$ν_i$ es el efecto específico de una persona.</p><p>Implication 4c</p><blockquote><p>The variability vs. noise problem becomes even more serious when the study contains a non-homogeneous sample
differing systematically in a feature that is not explicitly considered.
For example, based on how often they go to the doctor,
it seems that shorter students are ill more often than taller students.
However, this fact has nothing to do with body size.
It is simply the case that female students are shorter than male students on average
and see the gynecologist much more often than male students see the urologist.
However, females see the gynecologist mainly for preventive medical checkups
and are by no means more often ill than male students.
Since students generally see doctors very infrequently, visits to the gynecologist weigh strongly in the statistics.
It is obvious how mis-interpretations can occur even in such simple examples.
In more complex situations such mis-interpretations are less easy to spot.
By the way, one should question whether it is good idea to make conclusions about illness frequency based on doctor visits.</p></blockquote><blockquote><p>In the past it was usually impossible to obtain significant results with small effect sizes
because data were scarce and handling large sample sizes was cumbersome.
Hence, n was usually small and only experiments with large effect sizes produced significant results.
This has changed largely because data collection has become cheap,
and it is possible to combine and handle millions of samples as, for example, in genetics.
For this reason, nowadays statistics is widely used not only for medium effects but also for very small effect sizes.
However, this development is not free of danger.
First of all, large sample sizes should not be confused with large effect sizes (Implication 2a).
Second, conclusions are often very difficult to draw, particularly, in so called cohort studies.
In cohort studies, for example, patients are compared with controls, or vegetarians are compared with meat eaters.
The two groups are defined by a given label.</p></blockquote><blockquote><p>The main problem with these, so called, cohort studies
is that there are too many factors that are causally relevant,
but cannot be controlled for.
To control for all these effects and the combinations,
sample sizes may need to be larger than the number of people on the planet.
In addition, is it really worth investigating 2 mm Hg?
If you want to lower your blood pressure,
a little bit of sport might do a good job
and is much cheaper than paying thousands of dollars for education.</p></blockquote><p>Implications 5b. Small Effects Sizes As shown,
studies with small effect sizes require extra care.
However, small effect size are not always problematic.
First, it is good to reduce the side effects of a drug that is consumed by millions of people,
even if it is only by 1%.
Second, many important discoveries started off with small effects;
but subsequent investigations refined the methods and produced bigger effects.</p><p>Implications 5c. Conclusions Importantly, both small and large sample sizes can be problematic.
It is well known that small sample sizes are a problem because of undersampling.
It is less well understood that large sample sizes may be as problematic when effect sizes are small
because even tiny differences may become significant.
In particular, cohort studies with small effects sizes and large sample sizes are often useless
because small correlations between the investigated factor and unrelated factors
can create significant results.
For this reason, it is important to look at both the effect size and the sample size.
Whereas the sample size n is usually mentioned, this is not always true for effect sizes.
For the t-test, the effect size is often expressed as Cohen’s d (see also Chap. 4).
In the following chapters, we will introduce effect sizes for other tests.</p><blockquote><p>Take Home Messages</p><ol><li>Even small effect sizes lead to significant results when the sample size is sufficiently large.</li><li>Do not compare the p-value of two experiments if n is not identical: a smaller p does not imply more significance.</li><li>Statistical significance is not practical significance.</li><li>Absence of proof is not proof of absence: avoid conclusions from a Null result.</li><li>Do not pit a significant experiment against a non-significant control experiment.</li><li>Cohort studies with small effects are usually useless.</li><li>A statement like “X is true” can only be true for sure if inter-subject variability is zero.</li></ol></blockquote><p>Para la prueba t, los grados de libertad se calculan como $df = n_A + n_B - 2$. A partir de $n >= 1000$, el estadístico t es equivalente a $Z$.</p><h1 id=4-variantes-de-la-prueba-t><a href=#4-variantes-de-la-prueba-t alt>4. Variantes de la prueba t</a> <a href=# alt="Regresar al inicio">↑</a></h1><h2 id=suposiciones-de-la-prueba-t><a href=#suposiciones-de-la-prueba-t alt>Suposiciones de la Prueba T</a> <a href=# alt="Regresar al inicio">↑</a></h2><ul><li>Datos independientes e idénticamente distribuidos.</li><li>Distribución gaussiana.</li><li>Medidas en distribución de razón.</li><li>Varianzas iguales en ambos grupos.</li><li>Tamaño de muestra fijo.</li></ul><p><a href=http://www.ttable.org/ target=_blank rel=noopener>Consultar los valores de la prueba $t$</a></p><h2 id=alternativas><a href=#alternativas alt>Alternativas</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Cuando las varianzas son diferentes, se puede usar la prueba de Welch, que tiene menos poder para discriminar grupos con varianzas iguales.</p><table><thead><tr><th style=text-align:left>Parametric</th><th style=text-align:left>Non-parametric</th></tr></thead><tbody><tr><td style=text-align:left>One sample t-test</td><td style=text-align:left>Sign test</td></tr><tr><td style=text-align:left>Two-sample t-test</td><td style=text-align:left>Wilcoxon rank sum test</td></tr><tr><td style=text-align:left>Repeated measures t-test</td><td style=text-align:left>Man-Whitney U-test</td></tr></tbody></table><p>Las pruebas no paramétricas tienen menos poder porque no pueden aprovecharse del modelo.</p><p><a href=https://en.wikipedia.org/wiki/Nonparametric_statistics target=_blank rel=noopener>Las pruebas no-paramétricas suelen ser más robustas y simples pero tener menos poder estadístico</a></p><h1 id=5-el-problema-de-las-pruebas-múltiples><a href=#5-el-problema-de-las-pruebas-m%c3%baltiples alt>5. El problema de las pruebas múltiples</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>$P(falsos<del>positivos) = P(Error</del>Tipo<del>I) = 1 - (1 - α)^{número</del>de~pruebas}$</p><ol><li>You can only ask one question for a set of data.
Otherwise you need to account for multiple comparisons.</li><li>Keep your designs as simple as possible.</li><li>If you cannot keep your design simple and have more than one group comparison, read the next chapter.</li></ol><h2 id=anova-de-una-vía><a href=#anova-de-una-v%c3%ada alt>ANOVA de una vía</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Sinónimos para ANOVA de una vía con m-groups:</p><p>vía, factor</p><p>grupo, tratamiento, nivel</p><h3 id=suposiciones-de-la-anova-de-una-vía><a href=#suposiciones-de-la-anova-de-una-v%c3%ada alt>Suposiciones de la ANOVA de una vía</a> <a href=# alt="Regresar al inicio">↑</a></h3><ul><li>Muestras independientes</li><li>Poblaciones con distribución gaussiana</li><li>La variable independiente es discreta y la dependiente continua.</li><li>Grupos con varianzas iguales.</li><li>El tamaño de la muestra está determinado antes del experimento.</li></ul><table><thead><tr><th style=text-align:left>Tamaño de efecto ($η²$)</th><th style=text-align:left>Clasificación</th></tr></thead><tbody><tr><td style=text-align:left>0.01</td><td style=text-align:left>Pequeño</td></tr><tr><td style=text-align:left>0.09</td><td style=text-align:left>Mediano</td></tr><tr><td style=text-align:left>0.25</td><td style=text-align:left>Grande</td></tr></tbody></table><p>$F = \frac{ σ_{ entre~grupos } }{ σ_{ intragrupo } }$</p><p>(Este estadístico supone estricta normalidad, falla en caso contrario.)</p><p>$F = \frac{ \frac{ \sum_{j=1}^k \left( M_j - M_G \right)^2 }{ k - 1 } }{ \frac{ \sum_{i=1}^{n_j} \left( x_ij - M_j \right)^2 }{ n_j - 1 } }$</p><p>El tamaño del efecto $η^2$ se calcula:</p><p>$η^2 = \frac{ SS_{entre~grupos} }{ SS_{global} }$</p><p>$η^2 = \frac{ \sum_{j=1}^k n_j \left( \bar{x_j} - M_G \right)^2 }{ \sum_{j=1}^k \sum_{i=1}^{n_j} \left( x_{ij} - MG \right)^2 }$</p><h3 id=grados-de-libertad><a href=#grados-de-libertad alt>Grados de libertad</a> <a href=# alt="Regresar al inicio">↑</a></h3><p>Es el número de parámetros que podemos variar sin violar las restricciones del sistema.</p><p>$df_1 = k - 1$</p><p>$df_2 = n - k$</p><p>$df = df_1 + df_2 = n - 1$</p><p>$gl_{total} = gl_{entre~grupos} + gl_{intragrupo}$</p><p>$gl_{total} = grupos~(k) - mediciones~(media → 1) + valores~(n) - mediciones~(medias → k)$</p><p>$grados<del>de</del>libertad = observaciones - parámetros~estimados$</p><h2 id=anova-de-varias-vías><a href=#anova-de-varias-v%c3%adas alt>ANOVA de varias vías</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Para cada uno de los factores:</p><p>$H_0$: el factor no tiene efecto en la variable estudiada.</p><p>$H_0$: la interacción entre factores no tiene efecto en la variable estudiada.</p><p>Ganamos poder por la capacidad de detectar la interacción (parte del error se explica por la interacción de factores),
pero perdemos poder por cada factor que agregamos porque tenemos menos valores que contribuyen a cada media.</p><p>Las ANOVA de varias vías tienen el problema de las pruebas múltiples y por tanto $P(Aceptar<del>H_1 | H_1</del>es~falso)$ es mayor.</p><p><strong>NOTA</strong>: Si se encuentran interacciones significativas, no podemos concluir acerca del efecto principal, porque el efecto principal varía con respecto de la interacción de los factores.</p><p>¿Cómo se calculan los grados de libertad en la ANOVA de múltiples vías?</p><p>Para $Χ^2$ los grados de libertad son $df = filas \times columnas - 1$</p><p>Un ANOVA de 2x2 tiene 14% de probabilidades de encontrar al menos un resultado significativo en un conjunto de datos nulo.</p><h2 id=anova-con-medidas-repetidas><a href=#anova-con-medidas-repetidas alt>ANOVA con medidas repetidas</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Gana poder estadístico porque reduce la variabilidad midiendo la variabilidad en cada paciente antes de comparar la variabilidad entre pacientes.</p><h1 id=7-diseño-experimental-ajustes-de-modelos-poder-y-diseños-complejos><a href=#7-dise%c3%b1o-experimental-ajustes-de-modelos-poder-y-dise%c3%b1os-complejos alt>7. Diseño Experimental: Ajustes de Modelos, Poder y Diseños Complejos</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>Puedes mejorar el poder estadístico comprimiendo la información en una variable significativa u omitiendo información.</p><p>El proceso es dependiente del experimento.
Mientras más sencillo y menos variables tenga el experimento, mejor.</p><p>Si tu teoría requiere resultados significativos y resultados nulos, el poder estadístico se reduce enormemente.</p><p><strong>DUDA</strong>: ¿Cómo se calculan los grados de libertad de una ANOVA de múltiples vías?</p><h2 id=cómo-calcular-el-poder-de-un-diseño-experimental><a href=#c%c3%b3mo-calcular-el-poder-de-un-dise%c3%b1o-experimental alt>Cómo calcular el poder de un diseño experimental</a> <a href=# alt="Regresar al inicio">↑</a></h2><ol><li><p>Aumentar $δ = \frac{µ_1 - µ_2}{σ}$:</p><ul><li>Aumentar diferencia de medias.</li><li>Disminuir la varianza.</li><li>Aumentar el tamaño de muestra.</li></ul></li><li><p>Calcular el tamaño de muestra</p><ul><li>En función del modelo y el tamaño de efecto esperado.</li></ul></li><li><p>Simular las condiciones experimentales para buscar el óptimo experimental.</p></li></ol><h1 id=8-covarianza-y-correlaciones><a href=#8-covarianza-y-correlaciones alt>8. Covarianza y correlaciones</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>La covarianza es una generalización de la varianza porque $cov(x, x) = σ_x^2$.</p><p>$covarianza(x, y) = \frac{ \sum_{i=1}^n (x_i - \bar{X}) \times (y_1 -\bar{Y} )}{ n - 1 }$</p><p>La covarianza depende de la escala pero se normaliza con la desviación estándar de $x$ y $y$:</p><p>$r = \frac{ cov(x, y) }{ s_x s_y }$</p><p>Cuando se comparan las correlaciones, $H_0: ρ = 0$ y si esa hipótesis es verdad, $s_r = \sqrt{ \frac{ 1 - r^2 }{ n - 2 } }$ y se puede usar el estadístico $t$ donde:</p><p>$t = \frac{ r - 0 }{ s_r }$</p><p>$s_r = \sqrt{ \frac{ 1 - r^2 }{ n - 2 }}$</p><p>$df = observaciones (n) - parámetros (r, s_r: 2)$</p><p>$df = n - 2$</p><p><strong>DUDA</strong>: ¿Cómo se calcula la varianza de la correlación? y ¿Cómo se asegura uno que tiene distribución normal?</p><p><a href=https://es.wikipedia.org/wiki/Desviaci%C3%B3n_t%C3%ADpica target=_blank rel=noopener>desviación típica</a>:</p><p>$σ = \sqrt{ \frac{1}{n} \sum_{i = 1}^n (x_i - µ)^2 }$</p><p>$s = \sqrt{ \frac{1}{N-1} \sum_{i = 1}^{N} (x_i - \bar{X})^2 }$</p><p>Una correlación puede ser significativa puede ocurrir por:</p><ol><li>$x$ causa $y$</li><li>$y$ causa $x$</li><li>una variable diferente causa $x$ y $y$.</li><li>la correlación es espuria (por azar).</li></ol><p>Esta correlación sólo evalúa correlaciones lineales.</p><table><thead><tr><th style=text-align:left>Tamaño de efecto en (r)</th><th style=text-align:left>Clasificación</th></tr></thead><tbody><tr><td style=text-align:left>0.1</td><td style=text-align:left>Pequeño</td></tr><tr><td style=text-align:left>0.3</td><td style=text-align:left>Mediano</td></tr><tr><td style=text-align:left>0.5</td><td style=text-align:left>Grande</td></tr></tbody></table><p>$r^2$ puede interpretarse como $η^2$ (tamaño del efecto).</p><h3 id=comparación-entre-ajuste-de-modelo-anova-y-prueba-t><a href=#comparaci%c3%b3n-entre-ajuste-de-modelo-anova-y-prueba-t alt>Comparación entre ajuste de modelo, ANOVA y prueba $t$</a> <a href=# alt="Regresar al inicio">↑</a></h3><p>Cuando la variable independiente está en escala de razón, no conviene usar ANOVA.
En ese caso el ajuste a modelo tiene más poder que la ANOVA.</p><h3 id=suposiciones-para-correlación-de-pearson><a href=#suposiciones-para-correlaci%c3%b3n-de-pearson alt>Suposiciones para correlación de Pearson</a> <a href=# alt="Regresar al inicio">↑</a></h3><ol><li>Variables independientes y distribuidas idénticamente</li><li>La variable independiente está distribuida de manera normal para cada valor de x.</li><li>Ambas variables están en escala de proporción.</li><li>El tamaño de muestra es fijo antes del experimento.</li></ol><p>El equivalente no paramétrico de la correlación de Pearson es la correlación de Spearman.</p><h1 id=9-meta-análisis><a href=#9-meta-an%c3%a1lisis alt>9. Meta análisis</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>Cuando el tamaño de muestra es pequeño, el estimador $d = \frac{ \bar{x_1} - \bar{x_2} }{ s } = t \sqrt{\frac{ 2 }{ n }}$ sobreestima sistemáticamente el efecto en la población.</p><p>Para metaanálisis, se utiliza una corrección que se conoce como $g$ de Hedge:</p><p>$g = \left( 1 - \frac{ 3 }{4 (2n - 2) - 1} \right) d$</p><p>El efecto conjunto del metaanálisis se calcula:</p><p>$g^{*} = \frac{ \sum_{i = 1}^{experimentos} peso<del>ajustado_{experimento} \times g_{experimento} }{ \sum_{i = 1}^{experimentos} peso</del>ajustado_{experimento} }$</p><p>$peso~ajustado = \frac{ 1 }{ s_g }$</p><p>$s_g = \left( 1 - \frac{3}{ 4 (n_1 + n_2 - 2) - 1 } \right)^2 s_d$</p><p>$s_d = \frac{ n_1 + n_2 }{ n_1 n_2 } + \frac{ d^2 }{ 2 (n_1 + n_2) }$</p><h3 id=resumen><a href=#resumen alt>Resumen</a> <a href=# alt="Regresar al inicio">↑</a></h3><ol><li>Juntar el tamaño de efecto de varios experimentos mejora los estimados.</li><li>Combinar la información de varios experimentos aumenta el poder.</li></ol><h1 id=10-replicación><a href=#10-replicaci%c3%b3n alt>10. Replicación</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>La replicación de experimentos no es suficiente para probar la veracidad del efecto.</p><blockquote><p>Experiments should not always replicate, in particular, when effect and sample sizes are small.
Replication success should reflect the estimated success probabilities of experiments.
We should worry when experiments replicate too often.</p></blockquote><p>Para verificar los resultados de las publicaciones:</p><ol><li><p>Calcular el tamaño de efecto usando el estadístico $g*$.</p></li><li><p>Calcular el poder estadístico de cada estudio con el tamaño de efecto y tamaño de muestra.</p></li><li><p>Calcular el valor esperado de artículos publicados sumando el poder estadístico de los estudios.</p></li><li><p>Si el número de estudios correctos es cercano al valor esperado, los estudios parecen correctos.</p><p>En caso contrario esos experimentos no son evidencia científica válida y se necesitan más datos.</p></li></ol><h3 id=razones-por-las-que-los-experimentos-son-problemáticos><a href=#razones-por-las-que-los-experimentos-son-problem%c3%a1ticos alt>Razones por las que los experimentos son problemáticos</a> <a href=# alt="Regresar al inicio">↑</a></h3><ul><li><p>Sesgo de publicación.</p></li><li><p>Aumento opcional de muestras.</p></li><li><p>Realizar hipótesis después de conocer los resultados.</p></li><li><p>Análisis inapropiados.</p></li><li><p>Malentender las predicciones.</p></li><li><p>Revisión selectiva.</p><p>Recomendación de software: <code>[STATCHECK](https://github.com/MicheleNuijten/statcheck )</code>.</p></li></ul><h1 id=12-mejoras-sugeridas-y-retos><a href=#12-mejoras-sugeridas-y-retos alt>12. Mejoras sugeridas y retos</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>Publicar todos los resultados tiene el problema de confundir los errores metodológicos con el efecto del muestreo al azar.</p><hr><h2 id=preregistro><a href=#preregistro alt>Preregistro</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Se debe registrar un plan con:</p><ul><li>Experimento.</li><li>Métodos analíticos.</li><li>Plan de recolección de datos.</li></ul><p>Y registrar cualquier desviación con una justificación.</p><p>Previene hacer hipótesis después de conocer los datos.</p><h3 id=problemas><a href=#problemas alt>Problemas</a> <a href=# alt="Regresar al inicio">↑</a></h3><ul><li>No explica la justificación de generar una hipótesis.</li></ul><p>Los experimentadores diseñan sus experimentos usando:</p><ul><li>Una mezcla de ideas vagas</li><li>Intuición</li><li>Curiosidad</li><li>Resultados de experimentos pasados</li><li>Teorías cuantitativas</li></ul><p>Es imposible evaluar las partes vagas y el preregistro no cambia la situación.</p><h2 id=análisis-estadísticos-alternativos><a href=#an%c3%a1lisis-estad%c3%adsticos-alternativos alt>Análisis estadísticos alternativos</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=http://psych.purdue.edu/~gfrancis/EquivalentStatistics/ target=_blank rel=noopener>Convertir $p-value$ a otros estadísticos</a>.</p><p>Tenemos que aprender a usar el estadístico correcto para la pregunta que queremos contestar.</p><h2 id=el-rol-de-la-replicación><a href=#el-rol-de-la-replicaci%c3%b3n alt>El rol de la replicación</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>En física los experimentos son casi siempre deterministas.</p><p>En biología, psicología, sociología… las fuentes de ruido pueden reducirse pero los recursos y motivación de los investigadores no son suficientes para reducirlas al mismo grado.</p><p>En estas circunstancias se deben usar métodos estadísticos, prueba de hipótesis nula y en ocasiones habrá resultados inconsistentes debido a la variabilidad del muestreo.</p><p>Para que la replicación funcione, los estudios deben funcionar cada vez (alto poder) o debe existir una teoría que distinga entre la variabilidad de las muestras y la variabilidad de las medidas.</p><blockquote><p>As a final example, consider the effect of anesthesia.
The effect of isofluran, one type of anesthetic,
has been known for more than a century,
and it enables complicated surgeries that would otherwise be impossible.
Although the effects are very reliable,
the mechanism by which isofluran induces anesthesia is unknown.
Moreover, there are occasional failures where patients wake up in the middle of surgery
or subsequently have memories about the surgery.
If we understood the mechanisms by which isofluran induces anesthesia,
we might be able to anticipate and compensate for these failures.
Without a theory we do not know whether a failure is noise
or hints at some hidden mechanism.
In the meantime, doctors use anesthesia with the knowledge
that they need to be ready should there be a failures.</p></blockquote></article></main></body></html>