<!doctype html><html lang=es-mx><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Machine learning</title><link rel=stylesheet media=screen href=https://joshua.haase.mx/css/theme.min.c631e12f4e2b4b8b5282c3d94590678b7a225e8caccee02c0d37dac1838d6a61.css integrity="sha256-xjHhL04rS4tSgsPZRZBni3oiXoyszuAsDTfawYONamE="><script src=https://hypothes.is/embed.js></script></head><body><main><article><h1>Machine learning</h1><nav id=TableOfContents><ul><li><a href=#book-smart-y-el-aprendizaje-de-máquina>Book smart y el aprendizaje de máquina</a></li></ul></nav><p>Qué es el aprendizaje de máquina.</p><p>Qué métodos se utilizan,
para cada método:</p><ul><li>cuál es su objetivo</li><li>cuál es su fundamento matemático</li><li>cuáles son los supuestos del método</li></ul><p>Ejemplo aplicado de cada uno de ellos con un conjunto de datos.</p><p>Cómo podría construir un modelo predictivo para aplicarlo al análisis biológico.</p><h1 id=qué-es-al-aprendizaje-de-máquina><a href=#qu%c3%a9-es-al-aprendizaje-de-m%c3%a1quina alt>Qué es al aprendizaje de máquina</a> <a href=# alt="Regresar al inicio">↑</a></h1><p>El aprendizaje de máquina es el uso de algoritmos matemáticos para detectar patrones en la información.</p><p>La eficacia de esos patrones depende de la calidad de la información con que se alimenta y la definición de los objetivos.</p><p>Se pretende que sea posible entender cómo funcionan los modelos para la automatización de decisiones que influyen en la vida de las personas
pero a la fecha la mayoría de los modelos son inexplicables.</p><h2 id=book-smart-y-el-aprendizaje-de-máquina><a href=#book-smart-y-el-aprendizaje-de-m%c3%a1quina alt>Book smart y el aprendizaje de máquina</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Últimamente he estado reflexionando acerca de cómo puedes haber leído muchos libros y no saber cómo aplicarlos a la vida.</p><p>Me recordó el efecto de la <a href=https://towardsdatascience.com/zombies-model-rot-with-ml-engine-datastore-747b299526e9 target=_blank rel=noopener>erosión de la efectividad de los modelos de aprendizaje de máquina</a> y creo que es una buena analogía:</p><ul><li>Las personas que escriben libros dedicaron una parte importante de su vida a resolver un problema concreto en una situación concreta y utilizaron su [limitada capacidad de aprendizaje]( &ldquo;General Intelligence&rdquo;) para resolverlo, mediante ciclos de aprender patrones, actuar sobre ellos y olvidar los patrones que resultaron inefectivos. Luego pasaron por la difícil tarea de articular en lenguaje lo que hacen para poder enseñarlo.</li></ul><p>El resultado parece un modelo del problema que se quiere resolver donde se identifican el resultado que se pretende lograr, las características más relevantes para percibir el problema (features), la interacción entre características, probablemente agrupándolas en variables más informativas que incluyen y las múltiples maneras de actuar que son más efectivas para resolver el problema.</p><p>Como <a href=https://www.jordanbpeterson.com/docs/434/Assigned_Papers/Peterson%20JB%20Three%20Kinds%20of%20Meaning%20Final%203.pdf target=_blank rel=noopener>El problema más difícil de la inteligencia es la percepción</a> nos interesa leer libros porque «nos abren la mente» para percibir el mundo de una forma que nos permite resolver problemas.</p><p>Sin embargo, cada modelo sólo aplica en situaciones similares a donde fueron entrenados.</p><p>Los modelos aplican cuando se identifican correctamente las relaciones de causa y efecto.</p><p>Los modelos sólo pueden identificar correlación.
La causalidad se determina en función de los experimentos.</p><p>La <del>relación</del> eficacia de los modelos depende también de lo que sabemos de ellos.
Nuestra relación con los modelos es interactiva, porque cuando los usamos alteramos el entorno.
Si las correlaciones encontradas no eran causales, sino eran proxy de las verdaderas relaciones, el modelo pierde su efectividad muy rápidamente.</p><p>Las mediciones limitan el poder de nuestra capacidad de percepción.</p><p>Lo más importante del sistema es medir bien las cosas correctas
porque «la selección de características es lo que más impacto tiene en los resultados»
y «la medición es un acto humano y falible».</p><p>Leer un libro y cree que tiene la verdad porque hace sentido es común y sencillo.
El hecho de que en ciertos contextos tenga sentido un modelo, no implica que identifica correctamente la causalidad.</p><p>Parece que las ideas no son valiosas hasta que se actúan:
y por eso puede ser peligroso poner efectores directamente en los sistemas de inteligencia artificial
por el problema de Mickey Mouse en Fantasía.</p><blockquote><p>The critical skill for managers today
is to match those theories to their present situation
so that they apply the right advice at the right time.</p><p>The lean startup—Eric Ries</p></blockquote><h1 id=la-recolección-y-curación-de-datos-es-lo-más-costoso-y-difícil-de-los-proyectos-de-datos><a href=#la-recolecci%c3%b3n-y-curaci%c3%b3n-de-datos-es-lo-m%c3%a1s-costoso-y-dif%c3%adcil-de-los-proyectos-de-datos alt>La recolección y curación de datos es lo más costoso y difícil de los proyectos de datos</a> <a href=# alt="Regresar al inicio">↑</a></h1><h1 id=la-efectividad-de-los-modelos-debe-compararse-con-las-alternativas-que-se-usan-actualmente><a href=#la-efectividad-de-los-modelos-debe-compararse-con-las-alternativas-que-se-usan-actualmente alt><a href=https://www.linkedin.com/pulse/call-data-scientists-stop-using-measures-like-accuracy-jesse-heap target=_blank rel=noopener>La efectividad de los modelos debe compararse con las alternativas que se usan actualmente</a></a> <a href=# alt="Regresar al inicio">↑</a></h1><p>Para que funcione, la manera en que se evalúa el cumplimiento de las metas debe estar libre de errores
porque <a href=https://deepmind.com/blog/article/Specification-gaming-the-flip-side-of-AI-ingenuity target=_blank rel=noopener>los modelos de aprendizaje de máquina pueden aprender a cumplir sus metas diferente de cómo se espera</a></p><p>(Esto parece relacionarse con la definición de objetivos de «Clockwork—Mike Michalowicz»)</p><h1 id=ejemplos><a href=#ejemplos alt>Ejemplos</a> <a href=# alt="Regresar al inicio">↑</a></h1><p><a href=https://www.nature.com/articles/d41586-018-02174-z target=_blank rel=noopener>Las imágenes puede contener una gran cantidad de información biológica que puede procesarse con algoritmos de aprendizaje de máquina</a>.</p><p><a href=https://arxiv.org/abs/1412.6980 title=ADAM target=_blank rel=noopener>Un método para la optimización estocástica</a>.</p><p><a href=https://github.com/larspars/word-rnn target=_blank rel=noopener>El código de una red neural que usa palabras</a>.</p><p><a href=https://github.com/karpathy/char-rnn target=_blank rel=noopener>El código de una red neural que usa caracteres</a>.</p><p><a href=https://github.com/cyrildiagne/ar-cutpaste target=_blank rel=noopener>Código de plugin para Photoshop que pega objetos desde el entorno</a></p><p><a href=https://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735 target=_blank rel=noopener>Un algoritmo para aprendizaje de máquina que olvida la información vieja</a>.</p><p><a href=https://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/ target=_blank rel=noopener>Un experimento con redes neuronales recurrentes para generar clickbait</a>.</p><p><a href=https://thenewstack.io/aiops-greater-data-context-can-yield-richer-results/ target=_blank rel=noopener>Cómo puedes desarrollar tu flujo de trabajo para diseñar una empresa basada en datos</a>..</p><p><a href=https://www.technologyreview.com/2020/03/12/905352/ai-could-help-with-the-next-pandemicbut-not-with-this-one/ target=_blank rel=noopener>Se deben resolver problemas de acceso a la información, privacidad, coordinación y mecanismos de toma de decisión para que la IA sea útil para predecir el curso se una pandemia</a>. Hacer promesas que no se pueden cumplir podría perjudicar el campo nuevamente.</p><p><a href=https://towardsdatascience.com/zombies-model-rot-with-ml-engine-datastore-747b299526e9 target=_blank rel=noopener>Cómo predecir la efectividad de tu modelo y tomar retroalimentación para corregir el modelo cuando ya no funcione correctamente</a>.</p><p>Delip Rao cree que <a href=http://www.faqs.org/rfcs/rfc1925.html target=_blank rel=noopener>los principios de ingeniería de redes</a>
<a href=https://deliprao.com/archives/227 target=_blank rel=noopener>aplican directamente al aprendizaje de máquina</a>.</p><p><a href=/home/x/web/royalsocietypublishing.org/doi/pdf/10.1098/rsif.2017.0387>Oportunidades y retos para el aprendizaje de máquina en biología y medicina</a></p><hr><p><a href=https://ai-alignment.com/ target=_blank rel=noopener>AI Alignment: cómo evitar problemas de aprendizaje de Máquina</a>
recomendado por <a href=https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/ target=_blank rel=noopener>8000 hours para moldear positivamente el desarrollo del aprendizaje de máquina</a>.</p><p><a href=https://gym.openai.com/docs/ target=_blank rel=noopener>Entornos para entrenar algoritmos de aprendizaje de máquina compatibles con <code>TensorFlow</code> y <code>Theano</code></a>.</p><hr><p>@isbn:978-1541-67589-3 comenta que Geoffrey Hinton hace una contribución importante
al describir cómo los sistemas de aprendizaje de máquina usan marcos de referencia.
Por esa razón <a href='https://scholar.google.com/scholar?q=Geoffrey%20Hinton&amp;btnG=Search&amp;as_sdt=800000000001&amp;as_sdtp=on' target=_blank rel=noopener>busqué sus artículos en Google Scholar</a>
y encontré interesantes estos:</p><ul><li><p><a href=/home/x/web/direct.mit.edu/neco/article-pdf/18/7/1527/816558/neco.2006.18.7.1527.pdf title=[@doi:10.1162/neco.2006.18.7.1527]>A Fast Learning Algorithm for Deep Belief Nets</a></p></li><li><p><a href=/home/x/web/www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf>Dropout: A Simple Way to Prevent Neural Networks From Over fitting</a></p></li><li><p><a href=https://arxiv.org/abs/1503.02531 title=[@arXiv:1503.02531v1] target=_blank rel=noopener>Distilling the Knowledge in a Neural Network</a></p></li><li><p><a href=https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12 title=[@doi:10.1007/978-94-011-5014-9_12] target=_blank rel=noopener>A View of the Em Algorithm that Justifies Incremental, Sparse, and other Variants</a></p></li><li><p><a href=https://arxiv.org/abs/1207.0580 title=[@arXiv:1207.0580v1] target=_blank rel=noopener>Improving neural networks by preventing co-adaptation of feature detectors</a></p></li><li><p><a href=https://www.nature.com/articles/323533a0 title=[@doi:10.1038/323533a0] target=_blank rel=noopener>Learning representations by back-propagating errors</a></p></li></ul></article></main></body></html>