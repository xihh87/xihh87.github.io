[
  {
    "id": "attention",
    "URL": "https://arxiv.org/abs/1706.03762v5",
    "number": "1706.03762v5",
    "version": "v5",
    "title": "Attention Is All You Need",
    "issued": {
      "date-parts": [
        [
          2017,
          6,
          12
        ]
      ]
    },
    "author": [
      {
        "literal": "Ashish Vaswani"
      },
      {
        "literal": "Noam Shazeer"
      },
      {
        "literal": "Niki Parmar"
      },
      {
        "literal": "Jakob Uszkoreit"
      },
      {
        "literal": "Llion Jones"
      },
      {
        "literal": "Aidan N. Gomez"
      },
      {
        "literal": "Lukasz Kaiser"
      },
      {
        "literal": "Illia Polosukhin"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
  },
  {
    "id": "instructions",
    "URL": "https://arxiv.org/abs/2203.02155v1",
    "number": "2203.02155v1",
    "version": "v1",
    "title": "Training language models to follow instructions with human feedback",
    "issued": {
      "date-parts": [
        [
          2022,
          3,
          4
        ]
      ]
    },
    "author": [
      {
        "literal": "Long Ouyang"
      },
      {
        "literal": "Jeff Wu"
      },
      {
        "literal": "Xu Jiang"
      },
      {
        "literal": "Diogo Almeida"
      },
      {
        "literal": "Carroll L. Wainwright"
      },
      {
        "literal": "Pamela Mishkin"
      },
      {
        "literal": "Chong Zhang"
      },
      {
        "literal": "Sandhini Agarwal"
      },
      {
        "literal": "Katarina Slama"
      },
      {
        "literal": "Alex Ray"
      },
      {
        "literal": "John Schulman"
      },
      {
        "literal": "Jacob Hilton"
      },
      {
        "literal": "Fraser Kelton"
      },
      {
        "literal": "Luke Miller"
      },
      {
        "literal": "Maddie Simens"
      },
      {
        "literal": "Amanda Askell"
      },
      {
        "literal": "Peter Welinder"
      },
      {
        "literal": "Paul Christiano"
      },
      {
        "literal": "Jan Leike"
      },
      {
        "literal": "Ryan Lowe"
      }
    ],
    "container-title": "arXiv",
    "publisher": "arXiv",
    "type": "report",
    "abstract": "Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent."
  },
  {
    "id": "software2",
    "type": "post-weblog",
    "abstract": "I sometimes see people refer to neural networks as just “another tool in your machine learning toolbox”. They have some pros and cons, they…",
    "container-title": "Medium",
    "language": "en",
    "title": "Software 2.0",
    "URL": "https://karpathy.medium.com/software-2-0-a64152b37c35",
    "author": [
      {
        "family": "Karpathy",
        "given": "Andrej"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          2,
          15
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2021",
          3,
          13
        ]
      ]
    }
  },
  {
    "id": "fourier",
    "type": "webpage",
    "abstract": "Fourier transforms are a tool used in a whole bunch of different things. This is a explanation of what a Fourier transform does, and some different ways it can be useful.",
    "title": "An Interactive Introduction to Fourier Transforms",
    "URL": "http://www.jezzamon.com/fourier",
    "accessed": {
      "date-parts": [
        [
          "2023",
          2,
          15
        ]
      ]
    }
  },
  {
    "id": "gd",
    "type": "post-weblog",
    "abstract": "Do you wanna know What is Stochastic Gradient Descent?. Give your few minutes to this blog, to understand the Stochastic Gradient Descent completely in a",
    "container-title": "MLTut",
    "language": "en-US",
    "title": "What is Stochastic Gradient Descent- A Super Easy Complete Guide!",
    "URL": "https://www.mltut.com/stochastic-gradient-descent-a-super-easy-complete-guide/",
    "author": [
      {
        "literal": "aqsazafar"
      }
    ],
    "accessed": {
      "date-parts": [
        [
          "2023",
          2,
          15
        ]
      ]
    },
    "issued": {
      "date-parts": [
        [
          "2020",
          4,
          21
        ]
      ]
    }
  },
  {
    "id": "search",
    "type": "webpage",
    "abstract": "Plus: The original startup behind Stable Diffusion has launched a generative AI for video.",
    "container-title": "MIT Technology Review",
    "author": [
        {
        "literal": "MIT Technology Review"
        }
    ],
    "language": "en",
    "title": "Why you shouldn’t trust AI search engines",
    "URL": "https://www.technologyreview.com/2023/02/14/1068498/why-you-shouldnt-trust-ai-search-engines/",
    "issued": {
      "date-parts": [
        [
          "2023",
          2,
          14
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2023",
          2,
          15
        ]
      ]
    }
  },
  {
    "id": "karpathy",
    "type": "webpage",
    "title": "Neural Networks: Zero to Hero",
    "author": [
      {
        "family": "Karpathy",
        "given": "Andrej"
      }
    ],
    "URL": "https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ",
    "issued": {
      "date-parts": [
        [
          2017,
          6,
          12
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2023",
          2,
          15
        ]
      ]
    }
  }
]
