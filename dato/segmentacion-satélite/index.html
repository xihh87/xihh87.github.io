<!doctype html><html lang=es-mx><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Notas acerca de segmentación de imágenes por satélite</title><link rel=stylesheet media=screen href=https://joshua.haase.mx/css/theme.min.2ee1317322f9eb9b2ef0a618d19b20e38c11f5f9c310751400a45db225dd2626.css integrity="sha256-LuExcyL565su8KYY0Zsg44wR9fnDEHUUAKRdsiXdJiY="><script src=https://hypothes.is/embed.js></script></head><body><main><article><h1>Notas acerca de segmentación de imágenes por satélite</h1><nav id=TableOfContents><ul><li><a href=#calidad-de-la-información-disponible-groso-modo>Calidad de la información disponible (groso modo)</a></li><li><a href=#recursos>Recursos</a><ul><li><a href=#datos>Datos</a></li></ul></li><li><a href=#fuentes-de-información-abiertas>Fuentes de información abiertas</a></li><li><a href=#conclusiones-de-la-investigación>Conclusiones de la investigación</a></li></ul></nav><p><a href='https://www.tensorflow.org/tutorials/images/segmentation?hl=es-419' target=_blank rel=noopener>¿Qué es segmentación de imagen?</a></p><h2 id=calidad-de-la-información-disponible-groso-modo><a href=#calidad-de-la-informaci%c3%b3n-disponible-groso-modo alt>Calidad de la información disponible (groso modo)</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Las imágenes satelitales Lansat están disponibles desde 1989–2014.
Hay imágenes sentinel a partir de 2015.
(<a href=https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial target=_blank rel=noopener>resolución sentinel</a>)</p><h2 id=recursos><a href=#recursos alt>Recursos</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=https://github.com/satellite-image-deep-learning/techniques#2-segmentation target=_blank rel=noopener>Repo de enlaces de cómo tratar imágenes satelitales</a>
incluye qué modelos usar
y <a href=https://medium.com/@robmarkcole/a-brief-introduction-to-satellite-image-segmentation-with-neural-networks-33ea732d5bce target=_blank rel=noopener>explican los diferentes puntos de segmentación</a>.</p><p><a href=https://github.com/nasaharvest/togo-crop-mask target=_blank rel=noopener>Un modelo interesante para segmentar cultivos en regiones ralas como Togo, Africa</a> (<a href=https://arxiv.org/pdf/2006.16866.pdf title=[@arxiv:2006.16866] target=_blank rel=noopener>paper</a>, <a href=https://github.com/nasaharvest/togo-crop-mask target=_blank rel=noopener>código</a>)</p><p><a href=https://medium.com/geekculture/%D1%81r%D0%BE%D1%80-field-boundary-detection-approaches-and-main-challenges-46e37dd276bc target=_blank rel=noopener>Segmentación de cultivos usando detección de bordes</a> (<a href=https://www.mdpi.com/2072-4292/12/14/2240/htm title=[@doi:10.3390/rs12142240] target=_blank rel=noopener>paper</a>).</p><p><a href='https://www.researchgate.net/profile/David-Pairman/publication/329817494_Boundary_Delineation_of_Agricultural_Fields_in_Multitemporal_Satellite_Imagery/links/5c47f38d299bf12be3dc78f8/Boundary-Delineation-of-Agricultural-Fields-in-Multitemporal-Satellite-Imagery.pdf?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uIn19' title=[@doi:10.1109/JSTARS.2018.2884513] target=_blank rel=noopener>Detección de campos en imágenes satelitales multitemporales usando detección de bordes</a></p><p><a href=https://medium.com/radiant-earth-insights/detecting-agricultural-croplands-from-sentinel-2-satellite-imagery-a025735d3bd8 target=_blank rel=noopener>Unet-Agri juntó UNet y VGG-19</a>,
refieren a <a href=https://agrilinks.org/post/enhancing-earth-observation-solutions-agriculture-machine-learning target=_blank rel=noopener>este artículo</a>
donde explican que <a href=https://www.globenewswire.com/news-release/2019/12/09/1957957/0/en/Radiant-Earth-Foundation-Releases-World-s-First-Open-Repository-for-Geospatial-Training-Data.html target=_blank rel=noopener>publican sus datos</a> en
<a href=https://www.mlhub.earth/ target=_blank rel=noopener>Source Cooperative</a>
y <a href=https://www.globenewswire.com/news-release/2019/12/09/1957957/0/en/Radiant-Earth-Foundation-Releases-World-s-First-Open-Repository-for-Geospatial-Training-Data.html target=_blank rel=noopener>este tutorial para participar en un Agrinet India y supuestamente incluye</a>
cómo <a href=https://github.com/radiantearth/mlhub-tutorials/tree/main/tutorials/Guide%20to%20Accessing%20Data%20from%20Radiant%20MLHub target=_blank rel=noopener>descargar datos</a>.</p><p><a href=https://devseed.com/blog/2021-05-17-pearl-ai-land-cover target=_blank rel=noopener>PEARL → Ms para mapeo satelital</a>
(<a href=https://github.com/developmentseed/pearl-backend target=_blank rel=noopener>backend</a>).
<strong>No encontré el modelo</strong>.</p><p>Supuestamente hay un <a href=https://arxiv.org/pdf/1801.05746.pdf title=[@arxiv:1801.05746] target=_blank rel=noopener>modelo pre-entrenado UNet+VGG</a>
disponible como <a href=https://github.com/ternaus/TernausNet target=_blank rel=noopener>TernausNet</a> e instalable con pip
que tiene mejor desempeño que UNet solo.</p><p><a href=https://github.com/reachsumit/deep-unet-for-satellite-image-segmentation/tree/master target=_blank rel=noopener>Este proyecto entrena un UNet en datos satelitales de 8 bandas</a>.</p><p><a href=https://github.com/reachsumit/deep-unet-for-satellite-image-segmentation target=_blank rel=noopener>Otro repo de UNet</a>.</p><p><a href=https://towardsdatascience.com/semantic-segmentation-of-aerial-imagery-using-u-net-in-python-552705238514 target=_blank rel=noopener>Tutorial para entrenar una UNET para segmentar imágenes de satélite</a> y <a href=https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery target=_blank rel=noopener>dataset</a>.</p><p><a href=https://towardsdatascience.com/multi-label-land-cover-classification-with-deep-learning-d39ce2944a3d target=_blank rel=noopener>Otro tutorial para multi-clasificación</a></p><p><a href=https://github.com/YudeWang/UNet-Satellite-Image-Segmentation target=_blank rel=noopener>Repo que segmenta usando una UNET</a> que no es tan limpio como el anterior.</p><p><a href=https://github.com/lucasb-eyer/pydensecrf target=_blank rel=noopener>repo PyDenseCRF</a></p><p><a href=https://arxiv.org/pdf/1902.04099.pdf title=[@arxiv:1902.04099] target=_blank rel=noopener>Psi-Net Encoder-decoder con borde, máscara en paralelo</a></p><p><a href=https://arxiv.org/pdf/1910.12023.pdf title=[@arxiv:1910.12023v2] target=_blank rel=noopener>Artículo acerca de cómo extraer campos de imágenes de satélite</a></p><p><a href=https://github.com/VSainteuf/utae-paps target=_blank rel=noopener>Implementación U-TAE</a>,
<a href=https://github.com/rusty1s/pytorch_scatter target=_blank rel=noopener>biblioteca para actualización rala</a></p><p><a href=https://arxiv.org/abs/1911.07757 target=_blank rel=noopener>Otro modelo con auto-atención temporal</a></p><embed type=application/pdf src="https://openaccess.thecvf.com/content_CVPR_2020/papers/Garnot_Satellite_Image_Time_Series_Classification_With_Pixel-Set_Encoders_and_Temporal_CVPR_2020_paper.pdf#navpanes=0&statusbar=0&pagemode=none" width=100% height=905em><p><a href=https://openaccess.thecvf.com/content_CVPR_2020/papers/Garnot_Satellite_Image_Time_Series_Classification_With_Pixel-Set_Encoders_and_Temporal_CVPR_2020_paper.pdf>Descargar documento</a>.</p><h3 id=datos><a href=#datos alt>Datos</a> <a href=# alt="Regresar al inicio">↑</a></h3><ul><li><a href=https://nassgeodata.gmu.edu/CropScape/ target=_blank rel=noopener>Datos de clasificación de cultivo</a>.</li><li><a href=https://doi.pangaea.de/10.1594/PANGAEA.873912 target=_blank rel=noopener>Datos crowdsourced de área cultivable</a>.</li><li><a href=https://zenodo.org/records/3836629 target=_blank rel=noopener>Datos de cultivos en Togo</a>.</li><li><a href=https://github.com/chrieke/awesome-satellite-imagery-datasets target=_blank rel=noopener>Datasets de imágenes satelitales</a></li><li><a href=https://github.com/VSainteuf/pastis-benchmark target=_blank rel=noopener>PASTIS benchmark</a> contiene</li></ul><p>La <a href=https://zindi.africa/competitions/agrifieldnet-india-challenge/data target=_blank rel=noopener>competencia AgrifieldNet India</a>
tiene <a href=https://beta.source.coop/radiantearth/agrifieldnet-competition/ target=_blank rel=noopener>este conjunto de datos</a>
que contiene 1217 piezas de 256 x 256 px.</p><ul><li><p><input checked disabled type=checkbox> <a href=https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10#download-azcopy target=_blank rel=noopener>Descargar azcopy</a></p></li><li><p><input checked disabled type=checkbox> Descargar el conjunto de datos:</p><pre tabindex=0><code>mkdir -p ~/web/radiantearth.blob.core.windows.net/mlhub/ref_agrifieldnet_competition_v1
./azcopy sync https://radiantearth.blob.core.windows.net/mlhub/ref_agrifieldnet_competition_v1 ~/web/radiantearth.blob.core.windows.net/mlhub/ref_agrifieldnet_competition_v1  --recursive=true
</code></pre></li></ul><h2 id=fuentes-de-información-abiertas><a href=#fuentes-de-informaci%c3%b3n-abiertas alt>Fuentes de información abiertas</a> <a href=# alt="Regresar al inicio">↑</a></h2><ul><li><p>INEGI proporciona públicamente:</p><ul><li><a href=https://www.inegi.org.mx/temas/imagenes/imgAR/ target=_blank rel=noopener>imágenes de la república en diferentes momentos con resolución entre 1m y 30cm</a>.</li><li><a href='https://www.inegi.org.mx/app/biblioteca/ficha.html?upc=889463004776' target=_blank rel=noopener>modelos de elevación LiDAR</a>
en formatos <a href='https://www.inegi.org.mx/app/biblioteca/ficha.html?upc=889463004776' target=_blank rel=noopener>grid</a>
y <a href='https://www.inegi.org.mx/app/biblioteca/ficha.html?upc=889463000372' target=_blank rel=noopener>ASCII</a>
(via <a href='https://www.inegi.org.mx/app/buscador/default.html?q=imagenes+de+lidar+mexico' target=_blank rel=noopener>INEGI</a>,
<a href=https://mappinggis.com/2016/09/descargar-datos-lidar-gratis/#Datos_LiDAR_de_Mexico target=_blank rel=noopener>mappinggis</a>).</li></ul></li><li><p>Google proporciona de forma gratuita para proyectos de investigación:</p><ul><li><a href=https://developers.google.com/earth-engine/datasets/catalog/landsat target=_blank rel=noopener>Imágenes Landsat</a>.</li><li><a href=https://developers.google.com/earth-engine/datasets/catalog/sentinel target=_blank rel=noopener>Imágenes Sentinel</a>,
p.e.: <a href=https://developers.google.com/earth-engine/datasets/catalog/sentinel-2 target=_blank rel=noopener>MSI (13 bandas, 20m)</a>,
<a href=https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S1_GRD#bands target=_blank rel=noopener>polarización</a>.</li><li><a href=https://developers.google.com/earth-engine/datasets/tags/highres target=_blank rel=noopener>Imágenes de alta resolución</a>.</li><li><a href=https://developers.google.com/earth-engine/datasets/catalog/SKYSAT_GEN-A_PUBLIC_ORTHO_RGB#bands target=_blank rel=noopener>SkySAT RGB</a>.</li></ul><p>Estos datos pueden explorarse <a href='https://support.google.com/earth/answer/148094?hl=es-419&amp;sjid=13538121044670535642-NC' target=_blank rel=noopener>por tiempo</a>
y <a href='https://support.google.com/earth/answer/148095#connectors&amp;zippy=%2Celige-c%C3%B3mo-ver-tus-datos' target=_blank rel=noopener>por coordenadas</a>.
<a href=https://www.google.com/intl/es_es/earth/outreach/learn/introduction-to-google-earth-engine/ target=_blank rel=noopener>Este es el tutorial</a></p></li><li><p><del>NASA</del> proporciona <a href=https://search.earthdata.nasa.gov/search target=_blank rel=noopener>varios conjuntos de imágenes</a>,
pero <a href='https://search.earthdata.nasa.gov/search?fi=MULTI-SPECTRAL&amp;as[instrument][0]=MULTI-SPECTRAL&amp;fst0=Land%20Surface&amp;lat=19.399605086308924&amp;long=-100.6435546875&amp;zoom=7' target=_blank rel=noopener>no encontré imágenes multi-espectrales de México</a></p></li><li><p><a href=https://earthexplorer.usgs.gov/ target=_blank rel=noopener>United States</a></p></li><li><p><a href=https://developers.planet.com/docs/subscriptions/imagery-subs/ target=_blank rel=noopener>Planet</a>
permite comprar imágenes de un polígono en un espacio de tiempo,
o <a href=https://www.planet.com/products/monitoring/ target=_blank rel=noopener>monitorear un territorio diariamente</a>.
Tienen <a href=https://www.planet.com/products/platform/ target=_blank rel=noopener>este tipo de imágenes</a>.
Usan <a href=https://www.eoportal.org/satellite-missions/dove#spacecraft target=_blank rel=noopener>estos satélites</a>.</p></li><li><p><a href=https://www.satimagingcorp.com/services/ target=_blank rel=noopener>Satellite imaging Corp</a>
ofrece imágenes de</p></li></ul><p>Además se pueden explorar <a href=https://eos.com/blog/free-satellite-imagery-sources/ target=_blank rel=noopener>estas fuentes</a>,
<a href=https://paperswithcode.com/task/satellite-image-classification target=_blank rel=noopener>papers with code</a>,
<a href=https://github.com/topics/satellite-image-classification target=_blank rel=noopener>github</a>.</p><p><a href=https://journalofbigdata.springeropen.com/articles/10.1186/s40537-023-00772-x target=_blank rel=noopener>Uso de modelos clásicos de procesamiento de imágenes
para imágenes satelitales</a>.</p><p><a href=https://project.inria.fr/aerialimagelabeling/ target=_blank rel=noopener>Inria Aerial Image Labeling Dataset</a>.</p><p><a href='https://github.com/chrieke/awesome-satellite-imagery-datasets?tab=readme-ov-file' target=_blank rel=noopener>Lista de conjntos de datos para análisis de imágen satelital</a>.</p><p><a href='https://github.com/satellite-image-deep-learning/techniques?tab=readme-ov-file#datasets' target=_blank rel=noopener>Otra lista de conjuntos de datos</a>.</p><p><a href=https://github.com/Seyed-Ali-Ahmadi/Awesome_Satellite_Benchmark_Datasets target=_blank rel=noopener>Conjuntos de datos para evaluación</a>.</p><h2 id=conclusiones-de-la-investigación><a href=#conclusiones-de-la-investigaci%c3%b3n alt>Conclusiones de la investigación</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>La mayoría de los segmentadores con buen rendimiento están basados en <a href=https://arxiv.org/pdf/1505.04597.pdf title="[@arxiv:1505.04597v1] un modelo segmentador para imágenes biomédicas" target=_blank rel=noopener>UNet</a>
que puede descargarse <a href=https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-release-2015-10-02.tar.gz target=_blank rel=noopener>aquí</a>
<a href=https://developers.arcgis.com/python/api-reference/arcgis.learn.toc.html#unetclassifier target=_blank rel=noopener>ArcGIS tiene una implementación del modelo</a>.</p></article></main></body></html>