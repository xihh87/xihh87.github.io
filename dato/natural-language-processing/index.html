<!doctype html><html lang=es-mx><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Notas y enlaces acerca del Procesamiento del Lenguaje Natural</title><link rel=stylesheet media=screen href=https://joshua.haase.mx/css/theme.min.c631e12f4e2b4b8b5282c3d94590678b7a225e8caccee02c0d37dac1838d6a61.css integrity="sha256-xjHhL04rS4tSgsPZRZBni3oiXoyszuAsDTfawYONamE="><script src=https://hypothes.is/embed.js></script></head><body><main><article><h1>Notas y enlaces acerca del Procesamiento del Lenguaje Natural</h1><nav id=TableOfContents></nav><p><a href=https://arxiv.org/pdf/2005.14165.pdf title=[@arxiv:2005.14165v4] target=_blank rel=noopener>«Language Models are Few-Shot Learners»</a></p><p><a href=https://minimaxir.com/2019/09/howto-gpt2/ target=_blank rel=noopener>Un instructivo para usar GPT-2</a>
y <a href=https://openai.com/blog/better-language-models/ target=_blank rel=noopener>el post original de OpenAI</a>.</p><p><a href=https://arxiv.org/pdf/1801.10198.pdf target=_blank rel=noopener>El paper que describe cómo funciona GPT-3</a>.</p><p><a href=https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1 target=_blank rel=noopener>Propiedades emergentes de modelos de lenguaje</a></p></article></main></body></html>