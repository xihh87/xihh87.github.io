<!doctype html><html lang=es-mx><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Notas y enlaces acerca del Procesamiento del Lenguaje Natural</title><link rel=stylesheet media=screen href=https://joshua.haase.mx/css/theme.min.2ee1317322f9eb9b2ef0a618d19b20e38c11f5f9c310751400a45db225dd2626.css integrity="sha256-LuExcyL565su8KYY0Zsg44wR9fnDEHUUAKRdsiXdJiY="><script src=https://hypothes.is/embed.js></script></head><body><main><article><h1>Notas y enlaces acerca del Procesamiento del Lenguaje Natural</h1><nav id=TableOfContents></nav><p><a href=https://arxiv.org/pdf/2005.14165.pdf title=[@arxiv:2005.14165v4] target=_blank rel=noopener>«Language Models are Few-Shot Learners»</a></p><p><a href=https://minimaxir.com/2019/09/howto-gpt2/ target=_blank rel=noopener>Un instructivo para usar GPT-2</a>
y <a href=https://openai.com/blog/better-language-models/ target=_blank rel=noopener>el post original de OpenAI</a>.</p><p><a href=https://arxiv.org/pdf/1801.10198.pdf target=_blank rel=noopener>El paper que describe cómo funciona GPT-3</a>.</p><p><a href=https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1 target=_blank rel=noopener>Propiedades emergentes de modelos de lenguaje</a></p></article></main></body></html>