<!doctype html><html lang=es-mx><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Inteligencia artificial</title><link rel=stylesheet media=screen href=https://joshua.haase.mx/css/theme.min.2ee1317322f9eb9b2ef0a618d19b20e38c11f5f9c310751400a45db225dd2626.css integrity="sha256-LuExcyL565su8KYY0Zsg44wR9fnDEHUUAKRdsiXdJiY="><script src=https://hypothes.is/embed.js></script></head><body><main><article><h1>Inteligencia artificial</h1><nav id=TableOfContents><ul><li><a href=#enlaces-de-ai-para-el-curso-de-capacitación-en-el-nodo-de-huawei>Enlaces de AI para el curso de capacitación en el nodo de Huawei</a></li><li><a href=#hypes>Hypes</a></li><li><a href=#plataformas-interesantes-de-aprendizaje-de-máquina>Plataformas interesantes de aprendizaje de máquina</a></li><li><a href=#se-podría-usar-menos-cómputo-usando-redes-ralas>Se podría usar menos cómputo usando redes ralas</a></li><li><a href=#se-puede-optimizar-con-poco-usando-lora>Se puede optimizar con poco usando LoRA</a></li><li><a href=#algunos-llm>Algunos LLM</a></li><li><a href=#formas-para-inicializar-modelos>Formas para inicializar modelos</a></li><li><a href=#por-leer>POr leer</a></li></ul></nav><p><a href=https://www.technologyreview.com/2021/03/03/1020247/artificial-intelligence-brain-neuroscience-jeff-hawkins/ target=_blank rel=noopener>Jeff Hawkins argumenta que</a>:</p><ul><li>Aprendizaje de máquina no es inteligencia.</li><li>Para aprender de la inteligencia necesitamos entender los cerebros.</li><li>La inteligencia requiere tener un cuerpo para explorar la realidad.</li></ul><hr><p>Para producir máquinas rápidas no produjimos caballos mecánicos,
hicimos máquinas con ruedas que son más efectivas como máquinas.</p><p>Para la inteligencia muy probablemente ocurra algo similar, el enfoque más eficiente no tiene por qué parecerse a lo orgánico.</p><hr><p>EOL:
Pensar si sí somos “inteligentes” o seres orgánicos complejos
que de acuerdo a bases irracionales
creamos nuestra “racionalidad”.</p><hr><p>CAAR:
Como dicen los argumentos de AI: hay distintos tipos de inteligencia unos tangibles como nosotros e intangibles, inertes como la evolución y el caos.</p><hr><p>JAGO:
Si, aparte yo soy de la idea que una verdadera &ldquo;IA&rdquo; no tiene porque necesariamente asemejarse a nosotros.</p><p>No solo eso, es medio arrogante decir que la inteligencia debe de ser similar a nuestra &ldquo;inteligencia&rdquo;.</p><hr><p>LB:
<a href=https://www.sciencedirect.com/science/article/pii/S2666389920300210 target=_blank rel=noopener>@doi:10.1016/j.patter.2020.100021 propone limitar la inteligencia artificial para que sea segura</a></p><h2 id=enlaces-de-ai-para-el-curso-de-capacitación-en-el-nodo-de-huawei><a href=#enlaces-de-ai-para-el-curso-de-capacitaci%c3%b3n-en-el-nodo-de-huawei alt>Enlaces de AI para el curso de capacitación en el nodo de Huawei</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=https://intl-education-en.huaweicloud.com/courses/course-v1:HuaweiX+CBUENXE005+Self-paced/courseware/bff979a08a9c42539e66218245438f50/3c742aff3f8646c4bc051ef8307cd900/ target=_blank rel=noopener>Online course of AI overview</a></p><p><a href=https://intl-education-en.huaweicloud.com/courses/course-v1:HuaweiX+CBUENXE006+Self-paced/courseware/2397e9dbaec548f5a598f7e14f4f8cca/d227e7a82daa44808f3cd279f5aa09f8/ target=_blank rel=noopener>Online course of machine learning</a></p><p><a href=https://intl-education-en.huaweicloud.com/courses/course-v1:HuaweiX+CBUENXE008+Self-paced/courseware/d296381486d444db9e1adde5188de4a6/dcce54ea1afb4db49384430c65f8225e/ target=_blank rel=noopener>Online course of deep learning</a></p><p><a href=https://intl-education-en.huaweicloud.com/courses/course-v1:HuaweiX+CBUENXE007+Self-paced/courseware/1e6cac49669d4846b9654325fddf4917/210f23e5b8e14f2aa11048fd0cd44ad1/ target=_blank rel=noopener>Online course of mainstream AI framework</a></p><ul><li><a href=https://github.com/gliese581gg/YOLO_tensorflow target=_blank rel=noopener>YOLOV1</a></li><li><a href=https://arxiv.org/abs/1612.08242 target=_blank rel=noopener>YOLOV2</a></li><li><a href=https://arxiv.org/abs/1804.02767 target=_blank rel=noopener>YOLOV3</a></li></ul><p><a href=https://www.huaweicloud.com/intl/es-us/activity/tech_community/hcia_ia.html target=_blank rel=noopener>AI certification test</a></p><hr><p><a href='https://www.youtube.com/watch?v=IpGxLWOIZy4' target=_blank rel=noopener>Un video introductorio acerca de Machine Learning</a></p><p><a href=https://blog.netwrix.com/2020/09/02/data-classification/ target=_blank rel=noopener>Un pequeño tutorial acerca de clasificación de datos</a></p><hr><p><a href=https://stackoverflow.blog/2021/06/14/lets-enhance-use-intel-ai-to-increase-image-resolution-in-this-demo/ target=_blank rel=noopener>Un ejemplo de cómo utilizar AI para mejorar la calidad de las imágenes obtenidas a baja resolución</a>.</p><h2 id=hypes><a href=#hypes alt>Hypes</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=https://www.science.org/content/article/ai-learns-art-diplomacy-game target=_blank rel=noopener>&ldquo;IA aprende diplomacia&rdquo;</a>.</p><p><a href=https://deepimagination.cc/Magic3D/ target=_blank rel=noopener>Un modelo para generar modelos en 3D a partir de texto</a>.</p><h2 id=plataformas-interesantes-de-aprendizaje-de-máquina><a href=#plataformas-interesantes-de-aprendizaje-de-m%c3%a1quina alt>Plataformas interesantes de aprendizaje de máquina</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=https://dashboard.komprehend.io/login# target=_blank rel=noopener>https://dashboard.komprehend.io/login#</a></p><p><a href=https://learn.meaningcloud.com/developer/text-classification/2.0/dev-tools target=_blank rel=noopener>https://learn.meaningcloud.com/developer/text-classification/2.0/dev-tools</a></p><hr><p>Usando montones de parámetros,
hemos encontrado la forma de hacer
<a href=https://openai.com/blog/chatgpt/ target=_blank rel=noopener>robots que pueden conversar</a>
e ir refinando las entradas o pedir información.</p><p><a href=https://openai.com/blog/instruction-following/ target=_blank rel=noopener>OpenAI intenta que los robots puedan seguir instrucciones</a>.
El resultado <a href=https://www.nbcnews.com/tech/tech-news/chatgpt-ai-chatbot-viral-rcna59628 target=_blank rel=noopener>es tan sorprendente que sale en las noticias</a>
y <a href=https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/ title="100 millones de usuarios en dos meses." target=_blank rel=noopener>se convierte en la aplicación de mayor adopción en la historia de la humanidad</a>.</p><p><a href=https://www.semianalysis.com/p/google-we-have-no-moat-and-neither target=_blank rel=noopener>Un supuesto reporte filtrado de Google diciendo que los modelos abiertos van ganando</a> (tiene varios enlaces a modelos).
Y <a href=https://arstechnica.com/tech-policy/2023/07/chatgpts-user-base-shrank-after-openai-censored-harmful-responses/2/ target=_blank rel=noopener>una noticia que afirma que la gente deja de usar ChatGPT para usar modelos abiertos</a>.</p><hr><p>[Uso</p><hr><p>¿Agregar tridimensionalidad a los sistemas de aprendizaje de máquina podría hacerlos aprender diferente?</p><p>¿Qué pasa al entrenar matrices equivalentes a funciones matemáticas?</p><p>Si tuviéramos un método para generar modelos,
y los entrenáramos en módulos que</p><h2 id=se-podría-usar-menos-cómputo-usando-redes-ralas><a href=#se-podr%c3%ada-usar-menos-c%c3%b3mputo-usando-redes-ralas alt>Se podría usar menos cómputo usando redes ralas</a> <a href=# alt="Regresar al inicio">↑</a></h2><p>Las redes neuronales pueden reducirse en tamaño
<a href=https://arxiv.org/pdf/1911.09723.pdf title="Fast Sparse Convnets" target=_blank rel=noopener>si se entrenan únicamente los factores ralos</a> [@arxiv:1911.09723]
y <a href=https://www.graphcore.ai/products/ipu target=_blank rel=noopener>hay hardware dedicado para redes ralas</a>
(via <a href=https://medium.com/ibm-data-ai/do-neural-networks-really-need-to-be-so-big-6348047f43c0 target=_blank rel=noopener>Jonathan Frankle</a>).</p><p>Los modelos ralos no se usan tanto
porque los sistemas optimizados para trabajar redes ralas
no son muy populares.</p><p>Se puede modificar la función ¿de la red?
para optimizar qué conexiones afectan más la función de pérdida
y generar redes ralas y efectivas
[@arxiv:1810.02340].</p><p>El modelo ralo no ajusta etiquetas aleatorias,
por lo que SNIP podría usarse como prueba de ¿relevancia?
[@arxiv:1810.02340, p. X].</p><h2 id=se-puede-optimizar-con-poco-usando-lora><a href=#se-puede-optimizar-con-poco-usando-lora alt>Se puede optimizar con poco usando LoRA</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=https://arxiv.org/pdf/2106.09685.pdf target=_blank rel=noopener>Low Rank Adaptation of LLM</a>.</p><h2 id=algunos-llm><a href=#algunos-llm alt>Algunos LLM</a> <a href=# alt="Regresar al inicio">↑</a></h2><ul><li><a href=https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view target=_blank rel=noopener>Open Assistant</a></li><li><a href=https://bair.berkeley.edu/blog/2023/04/03/koala/ target=_blank rel=noopener>Koala</a></li></ul><h2 id=formas-para-inicializar-modelos><a href=#formas-para-inicializar-modelos alt>Formas para inicializar modelos</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=https://towardsdatascience.com/all-ways-to-initialize-your-neural-network-16a585574b52 target=_blank rel=noopener>Este artículo dice</a>:</p><ul><li>Zero</li><li>Aleatorioa</li><li><a href=http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf target=_blank rel=noopener>Xavier</a> (por varianza, para sigmoides)</li><li><a href=https://arxiv.org/pdf/1502.01852v1.pdf target=_blank rel=noopener>He: Inicialización por varianza para ReLU</a></li></ul><p><a href=https://link.springer.com/article/10.1007/s10462-021-10033-z target=_blank rel=noopener>Review</a>.</p><ul><li><a href=https://arxiv.org/abs/1901.09321 target=_blank rel=noopener>Fixup</a></li><li><a href=https://arxiv.org/abs/1511.06422 target=_blank rel=noopener>LSUV</a></li><li>Transfer learning</li></ul><h2 id=por-leer><a href=#por-leer alt>POr leer</a> <a href=# alt="Regresar al inicio">↑</a></h2><p><a href=#ZgotmplZ>Estimando el flujo de información en Redes Neuronales Profundas</a></p><ul><li><input disabled type=checkbox> <a href=https://christophm.github.io/interpretable-ml-book/interpretability-importance.html target=_blank rel=noopener>El libro del Aprendizaje de máquina interpretable</a></li></ul></article></main></body></html>